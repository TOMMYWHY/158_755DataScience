{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Precessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to the massive amount of data, we use a small amount of data for the demonstration on the local server to save time and use the entire data set for the Kaggle platform prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Load the data and analysis libraries\n",
    "> ### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "# import gc\n",
    "import numpy as np, pandas as pd\n",
    "import time\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### There are some configuration parameters. Use the following controls parameter IS_LOCAL_DEMO to switch between the Kaggle platform and local test. We used day_1750 as the first day and loaded all sales_train_validation for training on the Kaggle platform editor. For a local test demo, we use 1000 rows and form day_1850."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOCAL_DEMO = True\n",
    "# IS_LOCAL_DEMO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "last_day = 1913  # the last day for trian\n",
    "fday = datetime(2016,4, 25)  # the first predict day\n",
    "first_day = (1850 if (IS_LOCAL_DEMO) else 1750)\n",
    "demo_rows = (10000 if (IS_LOCAL_DEMO) else None) # the parameter just for quick local demo. should be all \n",
    "print(demo_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Due to the vast amount of data, we need to change the data type to reduce the pressure on memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }\n",
    "prices = pd.read_csv(\"../datasets/sell_prices.csv\", dtype = PRICE_DTYPES)\n",
    "\n",
    "for col, col_dtype in PRICE_DTYPES.items():\n",
    "    if col_dtype == \"category\":\n",
    "        prices[col] = prices[col].cat.codes.astype(\"int16\")  \n",
    "        prices[col] -= prices[col].min()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "         \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "        \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "cal = pd.read_csv(\"../datasets/calendar.csv\", dtype = CAL_DTYPES)\n",
    "\n",
    "cal[\"date\"] = pd.to_datetime(cal[\"date\"]) \n",
    "for col, col_dtype in CAL_DTYPES.items():\n",
    "    if col_dtype == \"category\":\n",
    "        cal[col] = cal[col].cat.codes.astype(\"int16\") \n",
    "        cal[col] -= cal[col].min() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Selecting only the columns and dates we need for the prediction can significantly reduce the computational pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 70)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1850</th>\n",
       "      <th>d_1851</th>\n",
       "      <th>d_1852</th>\n",
       "      <th>d_1853</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1850  d_1851  d_1852  d_1853  ...  d_1904  d_1905  d_1906  \\\n",
       "0       CA     0.0     4.0     0.0     1.0  ...     1.0     3.0     0.0   \n",
       "1       CA     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2       CA     1.0     0.0     0.0     0.0  ...     2.0     1.0     2.0   \n",
       "\n",
       "   d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0     1.0     1.0     1.0     3.0     0.0     1.0     1.0  \n",
       "1     0.0     0.0     1.0     0.0     0.0     0.0     0.0  \n",
       "2     1.0     1.0     1.0     0.0     1.0     1.0     1.0  \n",
       "\n",
       "[3 rows x 70 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numcols = [f\"d_{day}\" for day in range(first_day, last_day + 1)] # select dates\n",
    "catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "dtype = {numcol: \"float32\" for numcol in numcols}   \n",
    "dtype.update({col: \"category\" for col in catcols if col != \"id\"})  # Except for id, change others to type of category \n",
    "\n",
    "train_data = pd.read_csv(\"../datasets/sales_train_validation.csv\", usecols = catcols + numcols, dtype = dtype,\n",
    "                         nrows=demo_rows )  # The parameter will be None when runing on kaggle\n",
    "print(train_data.shape)\n",
    "# print(train_data.info())\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ###  Using OneHotEncoder should be getting a better result. However, it will make the data frame several times more massive. We use a compromise method to the part of feature values to meaningless digitize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in catcols:\n",
    "    if col != \"id\":\n",
    "        train_data[col] = train_data[col].cat.codes.astype(\"int16\")  # change the value to int\n",
    "        train_data[col] -= train_data[col].min()\n",
    "\n",
    "for day in range(last_day + 1, last_day + 28 +1): \n",
    "    train_data[f\"d_{day}\"] = np.nan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Change the data frame structure and merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.melt(train_data,\n",
    "              id_vars = catcols,\n",
    "              value_vars = [col for col in train_data.columns if col.startswith(\"d_\")],\n",
    "              var_name = \"d\",\n",
    "              value_name = \"sales\")\n",
    "\n",
    "train_data = train_data.merge(cal, on= \"d\", copy = False)\n",
    "train_data = train_data.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"d\"]=train_data[\"d\"].apply(lambda x: int(x.split(\"_\")[1])) # d_1 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Dataset Persistence\n",
    ">###  Save the data frame to the hard drive and shut down this script could release the space of memory.\n",
    ">### We save the data frame as \"train_data.csv.gz\" for the local demo and \"train_data.csv\" for the Kaggle platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(IS_LOCAL_DEMO):\n",
    "    train_data.to_csv(\"train_data.csv.gz\",compression='gzip',index=False)# for local demo\n",
    "else:\n",
    "    train_data.to_csv(\"train_data.csv\",index=False) # for kaggle  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

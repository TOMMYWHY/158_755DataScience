{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling : lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }\n",
    "# prices = pd.read_csv(\"../datasets/sell_prices.csv\", dtype = PRICE_DTYPES)\n",
    "# for col, col_dtype in PRICE_DTYPES.items():\n",
    "#     if col_dtype == \"category\":\n",
    "#         prices[col] = prices[col].cat.codes.astype(\"int16\")  # 类似于labelencoder，将store_id和item_id数字化表示\n",
    "#         prices[col] -= prices[col].min()  \n",
    "# # prices.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "#          \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "#         \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "# cal = pd.read_csv(\"../datasets/calendar.csv\", dtype = CAL_DTYPES)\n",
    "# cal[\"date\"] = pd.to_datetime(cal[\"date\"])  #  转化为datetime类型\n",
    "# for col, col_dtype in CAL_DTYPES.items():\n",
    "#     if col_dtype == \"category\":\n",
    "#         cal[col] = cal[col].cat.codes.astype(\"int16\")  # 将event_name_1/event_type_1/event_name_2/event_type_2weekday数字化表示\n",
    "#         cal[col] -= cal[col].min()  # NaN会转换为-1，该代表将NaN归为0，其他从1开始\n",
    "# # cal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOCAL_DEMO = True\n",
    "# IS_LOCAL_DEMO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lags = 57\n",
    "last_day = 1913  \n",
    "fday = datetime(2016,4, 25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: train_data.csv.gz\n"
     ]
    }
   ],
   "source": [
    "data_file = (\"train_data.csv.gz\" if(IS_LOCAL_DEMO) else \"train_data.csv\")\n",
    "dt = pd.read_csv(data_file)\n",
    "\n",
    "print(\"loading:\",data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"date\"] = pd.to_datetime(dt[\"date\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %time\n",
    "# first_day = 1850\n",
    "# numcols = [f\"d_{day}\" for day in range(first_day, last_day + 1)]  # 选取历史数据，从first_day到tr_last（包含这一天）d_1200,d_1201\n",
    "# catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "# dtype = {numcol: \"float32\" for numcol in numcols}   # d_1200为float32\n",
    "\n",
    "# dtype.update({col: \"category\" for col in catcols if col != \"id\"})  # 除id外，都为category类型\n",
    "# dt = pd.read_csv(\"../datasets/sales_train_validation.csv\", usecols = catcols + numcols, dtype = dtype,nrows=nrows_demo)  # 取catcols和numcols的列(只取了需要的历史天数销量数据)\n",
    "# dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for col in catcols:\n",
    "#         if col != \"id\":\n",
    "#             dt[col] = dt[col].cat.codes.astype(\"int16\")  # 数字化\n",
    "#             dt[col] -= dt[col].min()\n",
    "    \n",
    "    \n",
    "# for day in range(last_day + 1, last_day + 28 +1):  # 遍历预测的每一天\n",
    "#     dt[f\"d_{day}\"] = np.nan  # 先填充为NaN\n",
    "\n",
    "# dt = pd.melt(dt,\n",
    "#               id_vars = catcols,\n",
    "#               value_vars = [col for col in dt.columns if col.startswith(\"d_\")],\n",
    "#               var_name = \"d\",\n",
    "#               value_name = \"sales\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# dt = dt.merge(cal, on= \"d\", copy = False)\n",
    "# dt = dt.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt[\"d\"]=dt[\"d\"].apply(lambda x: int(x.split(\"_\")[1])) # d_1 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):  # [(7, lag_7), (28, lag_28)]\n",
    "        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)  \n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean()) \n",
    "\n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "\n",
    "    }\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fea(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'd',\n",
       "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_7', 'lag_28',\n",
       "       'rmean_7_7', 'rmean_28_7', 'rmean_7_28', 'rmean_28_28', 'week',\n",
       "       'quarter', 'mday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'wday', 'month',\n",
      "       'year', 'event_type_1', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI',\n",
      "       'sell_price', 'lag_7', 'lag_28', 'rmean_7_7', 'rmean_28_7',\n",
      "       'rmean_7_28', 'rmean_28_28', 'week', 'quarter', 'mday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_feats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + [\"event_type_1\", \"event_type_2\"]\n",
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\", 'event_name_1', 'event_name_2']\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "print(train_cols)\n",
    "X_train = df[train_cols]\n",
    "y_train = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(777)\n",
    "\n",
    "# size = (1_000 if(IS_LOCAL_DEMO) else 1_000_000)\n",
    "\n",
    "fake_valid_inds = np.random.choice(X_train.index.values, 1_000, replace = False)  \n",
    "# print(fake_valid_inds)\n",
    "print(len(fake_valid_inds))\n",
    "\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds) \n",
    "train_data = lgb.Dataset(X_train.loc[train_inds] , label = y_train.loc[train_inds], \n",
    "                         categorical_feature=cat_feats, free_raw_data=False)\n",
    "fake_valid_data = lgb.Dataset(X_train.loc[fake_valid_inds], label = y_train.loc[fake_valid_inds],\n",
    "                              categorical_feature=cat_feats,\n",
    "                 free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\" : \"poisson\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "#         \"nthread\" : 4\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 2000,\n",
    "    'num_leaves': 128,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.3788\n",
      "[200]\tvalid_0's rmse: 2.38309\n",
      "[300]\tvalid_0's rmse: 2.40137\n",
      "[400]\tvalid_0's rmse: 2.41032\n",
      "[500]\tvalid_0's rmse: 2.42431\n",
      "[600]\tvalid_0's rmse: 2.4241\n",
      "[700]\tvalid_0's rmse: 2.42064\n",
      "[800]\tvalid_0's rmse: 2.42683\n",
      "[900]\tvalid_0's rmse: 2.43035\n",
      "[1000]\tvalid_0's rmse: 2.43143\n",
      "[1100]\tvalid_0's rmse: 2.44216\n",
      "[1200]\tvalid_0's rmse: 2.44418\n",
      "[1300]\tvalid_0's rmse: 2.44771\n",
      "[1400]\tvalid_0's rmse: 2.45553\n",
      "[1500]\tvalid_0's rmse: 2.46243\n",
      "[1600]\tvalid_0's rmse: 2.46571\n",
      "[1700]\tvalid_0's rmse: 2.46487\n",
      "[1800]\tvalid_0's rmse: 2.47072\n",
      "[1900]\tvalid_0's rmse: 2.47643\n",
      "[2000]\tvalid_0's rmse: 2.47853\n"
     ]
    }
   ],
   "source": [
    "m_lgb = lgb.train(params, train_data, valid_sets = [fake_valid_data], verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "if(IS_LOCAL_DEMO):\n",
    "    alphas = [1] # for local demo\n",
    "else:\n",
    "    alphas = [1.035, 1.03, 1.025] #[1.015,1.25,1.03] #[1.0,1.15,1.01] #[1.0,1.15,1.01] # for kaggle\n",
    "\n",
    "weights = [1 / len(alphas)] * len(alphas) \n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-04-25 00:00:00\n",
      "0 2016-04-26 00:00:00\n",
      "0 2016-04-27 00:00:00\n",
      "0 2016-04-28 00:00:00\n",
      "0 2016-04-29 00:00:00\n",
      "0 2016-04-30 00:00:00\n",
      "0 2016-05-01 00:00:00\n",
      "0 2016-05-02 00:00:00\n",
      "0 2016-05-03 00:00:00\n",
      "0 2016-05-04 00:00:00\n",
      "0 2016-05-05 00:00:00\n",
      "0 2016-05-06 00:00:00\n",
      "0 2016-05-07 00:00:00\n",
      "0 2016-05-08 00:00:00\n",
      "0 2016-05-09 00:00:00\n",
      "0 2016-05-10 00:00:00\n",
      "0 2016-05-11 00:00:00\n",
      "0 2016-05-12 00:00:00\n",
      "0 2016-05-13 00:00:00\n",
      "0 2016-05-14 00:00:00\n",
      "0 2016-05-15 00:00:00\n",
      "0 2016-05-16 00:00:00\n",
      "0 2016-05-17 00:00:00\n",
      "0 2016-05-18 00:00:00\n",
      "0 2016-05-19 00:00:00\n",
      "0 2016-05-20 00:00:00\n",
      "0 2016-05-21 00:00:00\n",
      "0 2016-05-22 00:00:00\n",
      "0 1 1.0\n"
     ]
    }
   ],
   "source": [
    "sub = 0.\n",
    "cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):  # [(1.035, 0.333), (1.03, 0.333), (1.025, 0.333)]\n",
    "    te = dt\n",
    "\n",
    "    for tdelta in range(0, 28):\n",
    "        day = fday + timedelta(days=tdelta)  \n",
    "        print(icount, day)\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()  \n",
    "        create_fea(tst)\n",
    "        tst = tst.loc[tst.date == day , train_cols]  \n",
    "        te.loc[te.date == day, \"sales\"] = alpha * m_lgb.predict(tst)\n",
    "\n",
    "    te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]]\n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]  # [F1,F2,F3,...F28]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()  \n",
    "    te_sub.fillna(0., inplace = True) \n",
    "    te_sub.sort_values(\"id\", inplace = True)\n",
    "    te_sub.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    if icount == 0 :\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight\n",
    "    print(icount, alpha, weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 29)\n",
      "Index(['id', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',\n",
      "       'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20',\n",
      "       'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28'],\n",
      "      dtype='object', name='F')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>F</th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>0.882484</td>\n",
       "      <td>0.637337</td>\n",
       "      <td>0.562766</td>\n",
       "      <td>0.412774</td>\n",
       "      <td>1.037201</td>\n",
       "      <td>0.605822</td>\n",
       "      <td>0.923160</td>\n",
       "      <td>1.354341</td>\n",
       "      <td>0.865347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994954</td>\n",
       "      <td>1.378011</td>\n",
       "      <td>1.984383</td>\n",
       "      <td>2.968749</td>\n",
       "      <td>2.146219</td>\n",
       "      <td>1.748646</td>\n",
       "      <td>1.117743</td>\n",
       "      <td>1.193438</td>\n",
       "      <td>1.212587</td>\n",
       "      <td>1.692615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_2_validation</td>\n",
       "      <td>1.846428</td>\n",
       "      <td>1.633850</td>\n",
       "      <td>1.293822</td>\n",
       "      <td>1.306879</td>\n",
       "      <td>1.056510</td>\n",
       "      <td>1.562057</td>\n",
       "      <td>2.549772</td>\n",
       "      <td>1.568928</td>\n",
       "      <td>1.541383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024316</td>\n",
       "      <td>1.481218</td>\n",
       "      <td>2.501897</td>\n",
       "      <td>0.757024</td>\n",
       "      <td>1.418542</td>\n",
       "      <td>0.967959</td>\n",
       "      <td>1.409757</td>\n",
       "      <td>0.633885</td>\n",
       "      <td>0.854505</td>\n",
       "      <td>2.701530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_3_validation</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.281384</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.280363</td>\n",
       "      <td>0.282572</td>\n",
       "      <td>1.368990</td>\n",
       "      <td>2.009802</td>\n",
       "      <td>1.520692</td>\n",
       "      <td>1.505360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598873</td>\n",
       "      <td>0.958998</td>\n",
       "      <td>1.672139</td>\n",
       "      <td>0.671926</td>\n",
       "      <td>0.572143</td>\n",
       "      <td>0.587727</td>\n",
       "      <td>0.542686</td>\n",
       "      <td>0.418978</td>\n",
       "      <td>0.451443</td>\n",
       "      <td>1.836137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "F                           id        F1        F2        F3        F4  \\\n",
       "0  FOODS_1_001_CA_1_validation  0.882484  0.637337  0.562766  0.412774   \n",
       "1  FOODS_1_001_CA_2_validation  1.846428  1.633850  1.293822  1.306879   \n",
       "2  FOODS_1_001_CA_3_validation  0.363500  0.281384  0.311208  0.280363   \n",
       "\n",
       "F        F5        F6        F7        F8        F9  ...       F19       F20  \\\n",
       "0  1.037201  0.605822  0.923160  1.354341  0.865347  ...  0.994954  1.378011   \n",
       "1  1.056510  1.562057  2.549772  1.568928  1.541383  ...  1.024316  1.481218   \n",
       "2  0.282572  1.368990  2.009802  1.520692  1.505360  ...  0.598873  0.958998   \n",
       "\n",
       "F       F21       F22       F23       F24       F25       F26       F27  \\\n",
       "0  1.984383  2.968749  2.146219  1.748646  1.117743  1.193438  1.212587   \n",
       "1  2.501897  0.757024  1.418542  0.967959  1.409757  0.633885  0.854505   \n",
       "2  1.672139  0.671926  0.572143  0.587727  0.542686  0.418978  0.451443   \n",
       "\n",
       "F       F28  \n",
       "0  1.692615  \n",
       "1  2.701530  \n",
       "2  1.836137  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sub.shape)\n",
    "print(sub.columns)\n",
    "sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(IS_LOCAL_DEMO):\n",
    "    sub.to_csv(\"submission_lgb.csv.gz\",compression='gzip',index=False)# for local demo\n",
    "else:\n",
    "    sub.to_csv(\"submission_lgb.csv\",index=False) # for kaggle  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## LGB kaggle result ： 0.22838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

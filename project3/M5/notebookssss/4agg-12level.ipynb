{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "\n",
    "from ipywidgets import widgets, interactive, interact\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv(\"submission_knn.csv\") # for knn\n",
    "# sub=pd.read_csv(\"submission_rf.csv\") # for rf\n",
    "# sub=pd.read_csv(\"submission_xgb.csv\") # for xgb\n",
    "# sub=pd.read_csv(\"submission_lgm.csv\") # for lgm\n",
    "# sub=pd.read_csv(\"submission_mlp.csv\") # for mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales = pd.read_csv('../datasets/sales_train_validation.csv')\n",
    "submission_file = pd.read_csv('../datasets/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_col = ['id']\n",
    "sub_col.extend([f'd_{day}' for day in range(1914, 1914+28)])\n",
    "sub.columns = sub_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales = train_sales.merge(sub, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = ['Total']\n",
    "train_sales['Total'] = 'Total'\n",
    "train_sales['state_cat'] = train_sales.state_id + \"_\" + train_sales.cat_id\n",
    "train_sales['state_dept'] = train_sales.state_id + \"_\" + train_sales.dept_id\n",
    "train_sales['store_cat'] = train_sales.store_id + \"_\" + train_sales.cat_id\n",
    "train_sales['store_dept'] = train_sales.store_id + \"_\" + train_sales.dept_id\n",
    "train_sales['state_item'] = train_sales.state_id + \"_\" + train_sales.item_id\n",
    "train_sales['item_store'] = train_sales.item_id + \"_\" + train_sales.store_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_eval = ['validation', 'evaluation']\n",
    "\n",
    "# creating lists for different aggregation levels\n",
    "total = ['Total']\n",
    "states = ['CA', 'TX', 'WI']\n",
    "num_stores = [('CA',4), ('TX',3), ('WI',3)]\n",
    "stores = [x[0] + \"_\" + str(y + 1) for x in num_stores for y in range(x[1])]\n",
    "print(stores)  # 商店名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['FOODS', 'HOBBIES', 'HOUSEHOLD']\n",
    "num_depts = [('FOODS',3), ('HOBBIES',2), ('HOUSEHOLD',2)]\n",
    "depts = [x[0] + \"_\" + str(y + 1) for x in num_depts for y in range(x[1])]\n",
    "state_cats = [state + \"_\" + cat for state in states for cat in cats]\n",
    "state_depts = [state + \"_\" + dept for state in states for dept in depts]\n",
    "store_cats = [store + \"_\" + cat for store in stores for cat in cats]\n",
    "store_depts = [store + \"_\" + dept for store in stores for dept in depts]\n",
    "print(state_cats)  # 州名+大类\n",
    "print(\"=================================================================\")\n",
    "print(store_depts)  # 商店名（含州）+小类（含大类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = list(train_sales.item_id.unique())  # 商品列表\n",
    "prod_state = [prod + \"_\" + state for prod in prods for state in states]  # 商品（含大类和小类）+州名\n",
    "prod_store = [prod + \"_\" + store for prod in prods for store in stores]  # 商品（含大类和小类）+商店名（含州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = ['0.005', '0.025', '0.165', '0.250', '0.500', '0.750', '0.835', '0.975', '0.995']\n",
    "days = range(1, 1913 + 29)\n",
    "time_series_columns = [f'd_{i}' for i in days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sales(name_list, group):\n",
    "    '''\n",
    "    This function returns a dataframe (sales) on the aggregation level given by name list and group\n",
    "    '''\n",
    "    # rows_ve = [(name + \"_X_\" + str(q) + \"_\" + ve, str(q)) for name in name_list for q in quants for ve in val_eval]\n",
    "    sales = train_sales.groupby(group)[time_series_columns].sum() #would not be necessary for lowest level\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quantile_dict(name_list = stores, group = 'store_id' ,X = False):\n",
    "    '''\n",
    "    This function writes creates sales data on given aggregation level, and then writes predictions to the global dictionary my_dict\n",
    "    '''\n",
    "    sales = create_sales(name_list, group)\n",
    "    sales = sales.iloc[:, 1857:] #using the last few months data only\n",
    "    sales_quants = pd.DataFrame(index = sales.index)  # 空ataFrame，初始化为空\n",
    "    for q in quants:\n",
    "        sales_quants[q] = np.quantile(sales, float(q), axis = 1)  # 增加分位数的列，如CA_FOODS计算196天的0.005分位数\n",
    "    full_mean = pd.DataFrame(np.mean(sales, axis = 1))  #  新的DataFrame，只有一列，表示每个index最近196天的均值\n",
    "    daily_means = pd.DataFrame(index = sales.index)  # 新的DataFrame，初始化为空\n",
    "    for i in range(7):\n",
    "        daily_means[str(i)] = np.mean(sales.iloc[:, i::7], axis = 1)   # 新增7列，一周内每天的均值，如最近196天CA_FOOD,周一的均值\n",
    "        \n",
    "    daily_factors = daily_means / np.array(full_mean)\n",
    "    \n",
    "    daily_factors = pd.concat([daily_factors, daily_factors, daily_factors, daily_factors], axis = 1)\n",
    "    daily_factors_np = np.array(daily_factors)\n",
    "\n",
    "    factor_df = pd.DataFrame(daily_factors_np, columns = submission_file.columns[1:])\n",
    "    factor_df.index = daily_factors.index\n",
    "\n",
    "    for i,x in enumerate(tqdm(sales_quants.index)):\n",
    "        for q in quants:\n",
    "            v = sales_quants.loc[x, q] * np.array(factor_df.loc[x, :])\n",
    "            if X:\n",
    "                my_dict[x + \"_X_\" + q + \"_validation\"] = v\n",
    "                my_dict[x + \"_X_\" + q + \"_evaluation\"] = v\n",
    "            else:\n",
    "                my_dict[x + \"_\" + q + \"_validation\"] = v\n",
    "                my_dict[x + \"_\" + q + \"_evaluation\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "#adding prediction to my_dict on all 12 aggregation levels\n",
    "create_quantile_dict(total, 'Total', X=True) #1\n",
    "create_quantile_dict(states, 'state_id', X=True) #2\n",
    "create_quantile_dict(stores, 'store_id', X=True) #3\n",
    "create_quantile_dict(cats, 'cat_id', X=True) #4\n",
    "create_quantile_dict(depts, 'dept_id', X=True) #5\n",
    "create_quantile_dict(state_cats, 'state_cat') #6\n",
    "create_quantile_dict(state_depts, 'state_dept') #7\n",
    "create_quantile_dict(store_cats, 'store_cat') #8\n",
    "create_quantile_dict(store_depts, 'store_dept') #9\n",
    "create_quantile_dict(prods, 'item_id', X=True) #10\n",
    "create_quantile_dict(prod_state, 'state_item') #11\n",
    "create_quantile_dict(prod_store, 'item_store') #12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(my_dict)\n",
    "pred_df = pred_df.transpose()\n",
    "pred_df_reset = pred_df.reset_index()\n",
    "final_pred = pd.merge(pd.DataFrame(submission_file.id), pred_df_reset, left_on = 'id', right_on = 'index')\n",
    "del final_pred['index']\n",
    "final_pred = final_pred.rename(columns={0: 'F1', 1: 'F2', 2: 'F3', 3: 'F4', 4: 'F5', 5: 'F6', 6: 'F7', 7: 'F8', 8: 'F9',\n",
    "                                        9: 'F10', 10: 'F11', 11: 'F12', 12: 'F13', 13: 'F14', 14: 'F15', 15: 'F16',\n",
    "                                        16: 'F17', 17: 'F18', 18: 'F19', 19: 'F20', 20: 'F21', 21: 'F22', \n",
    "                                        22: 'F23', 23: 'F24', 24: 'F25', 25: 'F26', 26: 'F27', 27: 'F28'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = final_pred.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pred.to_csv('submission_xgb_final_small.csv', index=False)\n",
    "final_pred.to_csv('submission_knn_final_small.csv', index=False)\n",
    "# final_pred.to_csv('submission_xgb_final_small.csv', index=False)\n",
    "# final_pred.to_csv('submission_lgm_final_small.csv', index=False)\n",
    "# final_pred.to_csv('submission_mlp_final_small.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 16 (optional) - Analytics with SQLite and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Lecture 16 - Analytics with SQLite](#Lecture-16---Analytics-with-SQLite)\n",
    "\t* &nbsp;\n",
    "\t\t* [Learning Outcomes](#Learning-Outcomes)\n",
    "\t\t* [Create and populate SQLite tables](#Create-and-populate-SQLite-tables)\n",
    "        * [Subqueries](#Subqueries)\n",
    "        * [Creating Bins or Value bands](#Creating-Bins-or-Value-bands)\n",
    "        * [RFM with SQLite](#RFM-with-SQLite)\n",
    "        * [Classifying our customers using CASE statements](#Classifying-our-customers-using-CASE-statements)\n",
    "        * [Final exercise - Visits to store, target product](#Final-exercise---Visits-to-store,-target-product)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture we are going to practice creating and populating tables with SQLite.  We will look a bit more a subqueries and binning data.  We are then going to look at some basic analytics with SQLite and Pandas - namely binning customer data for the purposes of an RFM analysis.  Finally, there is a loyalty customer analysis exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this lecture, you should be able to:\n",
    "\n",
    "* Be more confident with defining a database schema with SQLite\n",
    "* Be more confident with iteratively populating database tables with SQLite\n",
    "* Use subqueries\n",
    "* Bin data with SQLite and visualise that data with python\n",
    "* Experiment with binning for the purposes of customer segmentation in an RFM analysis\n",
    "* Try a loyalty customer analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('../datasets/mySQLiteDB.sl3')\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and populate SQLite tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be using the product, line, invoice, vendor and customer tables from the first half of semester SQL content.  Csv versions of these are available on Stream in the datasets folder.  The invoice table has had dates altered to suit our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Read in \"product.csv\", \"line.csv\", \"vendor.csv\", \"invoice.csv\" and \"customer.csv\" into separate dataframes and check they have been imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build a schema for these tables (i.e. define all of the tables with constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS PRODUCT')\n",
    "\n",
    "table = \"\"\"\n",
    "            CREATE TABLE PRODUCT (\n",
    "            P_CODE VARCHAR2(10) CONSTRAINT PRODUCT_P_CODE_PK PRIMARY KEY,\n",
    "            P_DESCRIPT VARCHAR2(35) NOT NULL,\n",
    "            P_INDATE DATE NOT NULL,\n",
    "            P_QOH NUMBER NOT NULL,\n",
    "            P_MIN NUMBER NOT NULL,\n",
    "            P_PRICE NUMBER(8,2) NOT NULL,\n",
    "            P_DISCOUNT NUMBER(5,2) NOT NULL,\n",
    "            V_CODE NUMBER);\n",
    "            \"\"\"\n",
    "cursor.execute(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS CUSTOMER')\n",
    "table = \"\"\"\n",
    "            CREATE TABLE CUSTOMER (\n",
    "            CUS_CODE NUMBER PRIMARY KEY,\n",
    "            CUS_LNAME VARCHAR(15) NOT NULL,\n",
    "            CUS_FNAME VARCHAR(15) NOT NULL,\n",
    "            CUS_INITIAL CHAR(1),\n",
    "            CUS_AREACODE CHAR(3) DEFAULT '615' NOT NULL CHECK(CUS_AREACODE IN ('615','713','931')),\n",
    "            CUS_PHONE CHAR(8) NOT NULL,\n",
    "            CUS_BALANCE NUMBER(9,2) DEFAULT 0.00,\n",
    "            CONSTRAINT CUS_UI1 UNIQUE(CUS_LNAME,CUS_FNAME)\n",
    "            );\n",
    "                \"\"\"\n",
    "\n",
    "cursor.execute(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS LINE')\n",
    "table = \"\"\"\n",
    "        CREATE TABLE LINE (\n",
    "            INV_NUMBER NUMBER NOT NULL,\n",
    "            LINE_NUMBER NUMBER(2,0) NOT NULL,\n",
    "            P_CODE VARCHAR(10) NOT NULL,\n",
    "            LINE_UNITS NUMBER(9,2) DEFAULT 0.00 NOT NULL,\n",
    "            LINE_PRICE NUMBER(9,2) DEFAULT 0.00 NOT NULL,\n",
    "            PRIMARY KEY (INV_NUMBER,LINE_NUMBER),\n",
    "            CONSTRAINT LINE_UI1 UNIQUE(INV_NUMBER, P_CODE)\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS VENDOR')\n",
    "table = \"\"\"\n",
    "        CREATE TABLE VENDOR ( \n",
    "        V_CODE INTEGER, \n",
    "        V_NAME VARCHAR(35) NOT NULL, \n",
    "        V_CONTACT VARCHAR(15) NOT NULL, \n",
    "        V_AREACODE CHAR(3) NOT NULL, \n",
    "        V_PHONE CHAR(8) NOT NULL, \n",
    "        V_STATE CHAR(2) NOT NULL, \n",
    "        V_ORDER CHAR(1) NOT NULL, \n",
    "        PRIMARY KEY (V_CODE)\n",
    ");\n",
    "            \"\"\"\n",
    "cursor.execute(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Add the invoice table to the schema and commit() your changes to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to populate the tables iteratively using the substitution method from lecture 14.  First, we define row insertion statements for each table that as many placeholders as there are columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_row_product = \"\"\"\n",
    "                            INSERT INTO PRODUCT \n",
    "                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                        \"\"\"\n",
    "add_row_customer = \"\"\"\n",
    "                            INSERT INTO CUSTOMER \n",
    "                            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                        \"\"\"\n",
    "add_row_line = \"\"\"\n",
    "                            INSERT INTO LINE \n",
    "                            VALUES (?, ?, ?, ?, ?)\n",
    "                        \"\"\"\n",
    "add_row_vendor = \"\"\"\n",
    "                            INSERT INTO VENDOR \n",
    "                            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** create an insertion statement for the invoice table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iteratively populate our tables with a for loop, as we did in lecture 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in product.iterrows():\n",
    "    substitution_values = (row['P_CODE'], row['P_DESCRIPT'], row['P_INDATE'],\\\n",
    "                           row['P_QOH'], row['P_MIN'], row['P_PRICE'], \\\n",
    "                           row['P_DISCOUNT'], row['V_CODE'])\n",
    "    cursor.execute(add_row_product, substitution_values)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check\n",
    "sql_statement = 'SELECT * FROM PRODUCT;'\n",
    "cursor.execute(sql_statement)\n",
    "\n",
    "\n",
    "for (P_CODE, P_DESCRIPT, P_INDATE, P_QOH, P_MIN, P_PRICE, P_DISCOUNT,V_CODE) in cursor:\n",
    "    print(P_CODE, P_DESCRIPT, P_INDATE, P_QOH, P_MIN, P_PRICE, P_DISCOUNT,V_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in customer.iterrows():\n",
    "    substitution_values = (row['CUS_CODE'], row['CUS_LNAME'], row['CUS_FNAME'],\\\n",
    "                           row['CUS_INITIAL'], row['CUS_AREACODE'], row['CUS_PHONE'], \\\n",
    "                           row['CUS_BALANCE'])\n",
    "    cursor.execute(add_row_customer, substitution_values)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check\n",
    "sql_statement = 'SELECT * FROM CUSTOMER;'\n",
    "cursor.execute(sql_statement)\n",
    "\n",
    "\n",
    "for (CUS_CODE, CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, CUS_PHONE, CUS_BALANCE) in cursor:\n",
    "    print(CUS_CODE, CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, CUS_PHONE, CUS_BALANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in line.iterrows():\n",
    "    substitution_values = (row['INV_NUMBER'], row['LINE_NUMBER'], row['P_CODE'],\\\n",
    "                           row['LINE_UNITS'], row['LINE_PRICE'])\n",
    "    cursor.execute(add_row_line, substitution_values)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check\n",
    "sql_statement = 'SELECT * FROM LINE;'\n",
    "cursor.execute(sql_statement)\n",
    "\n",
    "\n",
    "for (INV_NUMBER, LINE_NUMBER, P_CODE, LINE_UNITS, LINE_PRICE) in cursor:\n",
    "    print(INV_NUMBER, LINE_NUMBER, P_CODE, LINE_UNITS, LINE_PRICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vendor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in vendor.iterrows():\n",
    "    substitution_values = (row['V_CODE'], row['V_NAME'], row['V_CONTACT'],\\\n",
    "                           row['V_AREACODE'], row['V_PHONE'], row['V_STATE'], \\\n",
    "                           row['V_ORDER'])\n",
    "    cursor.execute(add_row_vendor, substitution_values)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check\n",
    "sql_statement = 'SELECT * FROM VENDOR;'\n",
    "cursor.execute(sql_statement)\n",
    "\n",
    "\n",
    "for (V_CODE, V_NAME, V_CONTACT, V_AREACODE, V_PHONE, V_STATE, V_ORDER) in cursor:\n",
    "    print(V_CODE, V_NAME, V_CONTACT, V_AREACODE, V_PHONE, V_STATE, V_ORDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Insert the invoice rows into the invoice table and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subqueries\n",
    "A closer look at subqueries, using the pandas SQL methods.\n",
    "\n",
    "A subquery is a query embedded or nested inside another query.  The inner query will be executed first and the outer query will work with the result of the subquery.  \n",
    "\n",
    "Subqueries are wrapped up in parentheses.\n",
    "\n",
    "### With a projection clause (i.e. making a column with a subquery)\n",
    "\n",
    "We can use a subquery where we would put a column name.  You should give each subquery an alias to improve the readability of your query and also of the result set. \n",
    "\n",
    "Take the following query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT AVG(P_PRICE) FROM PRODUCT\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this as a subquery within the column list (projection) of another query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT \n",
    "                P_CODE, \n",
    "                P_PRICE, \n",
    "                (SELECT AVG(P_PRICE) FROM PRODUCT) AS \"AVERAGE PRICE\", \n",
    "                P_PRICE - (SELECT AVG(P_PRICE) FROM PRODUCT) AS DIFFERENCE\n",
    "                FROM PRODUCT;\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Alter the above query so that the difference between the product price and maximum product price is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With WHERE\n",
    "- Uses a SELECT subquery on the right side of a WHERE comparison expression\n",
    "- Value generated by the subquery must be of a comparable data type\n",
    "- Can be used in combination with joins\n",
    "\n",
    "Eg. to return a list of vendors who have not supplied products:\n",
    "\n",
    "First, let's look at a subquery that finds all vendor codes in the product table (this is a list of vendors that *have* supplied products):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT DISTINCT V_CODE FROM PRODUCT WHERE V_CODE IS NOT NULL;\n",
    "\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find return a list of vendors who have not supplied products, we would look for vendors in the vendor table who are not in the above list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT \n",
    "                V_CODE, \n",
    "                V_NAME \n",
    "                FROM VENDOR\n",
    "                WHERE V_CODE NOT IN \n",
    "                (SELECT DISTINCT V_CODE FROM PRODUCT WHERE V_CODE IS NOT NULL);\n",
    "\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Alter the above query so that we select from the vendor table only those vendors who have supplied mroe than one product.  A GROUP BY and HAVING clause will be needed in the subquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With HAVING\n",
    "- HAVING clause restricts the output of a GROUP BY query by applying conditional criteria to the grouped rows\n",
    "\n",
    "Eg., to list all products with total quantity sold greater than average quantity sold:\n",
    "\n",
    "First, a look at the subquery we will need:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT AVG(LINE_UNITS) FROM LINE;\n",
    "\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this in our HAVING clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT P_CODE, SUM(LINE_UNITS) TOTAL_UNITS FROM LINE\n",
    "                GROUP BY P_CODE\n",
    "                HAVING SUM(LINE_UNITS) > (SELECT AVG(LINE_UNITS) FROM LINE);\n",
    "\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that none of the products returned in the result set have sold less than three units\n",
    "\n",
    "**Exercise:** Alter the above query to select products that have in total sold less than the maximum number of items sold in any line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With FROM\n",
    "\n",
    "The FROM clause is where we specify the table that we are querying, e.g. to query the product table, we could use this query:\n",
    "\n",
    "> SELECT * FROM PRODUCT\n",
    "\n",
    "We can use a subquery with FROM rather than specify a table name.  Queries return result sets which in turn are tables themselves.  By using a subquery with the FROM clause, it is like creating a table on the fly from which we make our query.  \n",
    "\n",
    "The query below sums up customer spend to get a total spend for each customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT \n",
    "                I.CUS_CODE, \n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS Total_Spend\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY \n",
    "                I.CUS_CODE\n",
    "\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now query this as if it were an existing table by including it as a subquery after the FROM clause.  Note that we give the subquery a table alias that we refer to when selecting data from it (SUBQ in this case).  Here we select the average total spend from the table above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT\n",
    "                AVG(SUBQ.Total_Spend) as \"Average Total Customer Spend\"\n",
    "                FROM\n",
    "\n",
    "\n",
    "                (SELECT \n",
    "                I.CUS_CODE, \n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS Total_Spend\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY \n",
    "                I.CUS_CODE) SUBQ \n",
    ";\n",
    "\n",
    "\"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise:** Create a query that calculates the average total units sold across all products.  \n",
    "\n",
    "In the FROM subquery you will sum up the number of units sold for each product using the line table.  The outer query will then calculate the average total units sold across all products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bins or Value bands \n",
    "Often we want to bin customers or products up into value bands to get an idea of how many sit within each band.  For instance, we might want to know how many products cost up to \\\\$10, how many cost \\\\$10-\\\\$20, how many cost \\\\$20-\\\\$30 and so on.\n",
    "\n",
    "In Oracle SQL we might use CEIL or FLOOR to achieve this.  e.g. to show a $10 price band for products we could use this query:\n",
    "\n",
    ">SELECT FLOOR(P_PRICE/10)*10 FROM PRODUCT;\n",
    "\n",
    "For $50 price bands, we could use this query:\n",
    "\n",
    ">SELECT FLOOR(P_PRICE/50)*50 FROM PRODUCT;\n",
    "\n",
    "In SQLLite there is no CEIL or FLOOR, so we have to find another way.  \n",
    "\n",
    "The following formulae will work, but only when the value is greater than zero. \n",
    "    - The lower limit of the bin can be found with ROUND((VALUE - 0.5*<bin_width>)/<bin_width>, 0)*<bin_width> \n",
    "    - The upper limit of the bin can be found with ROUND((VALUE - 0.5*<bin_width>)/<bin_width>, 0)*<bin_width>\n",
    "   \n",
    "   \n",
    "So if we had bins of size 10, the calculations would be:\n",
    "\n",
    " - Lower = ROUND((VALUE - 5)/10, 0)*10\n",
    " - Upper = ROUND((VALUE + 5)/10, 0)*10\n",
    "\n",
    "And for bins of size 50, the calculations would be:\n",
    "\n",
    " - Lower = ROUND((VALUE - 25)/50, 0)*50\n",
    " - Upper = ROUND((VALUE + 25)/50, 0)*50\n",
    "\n",
    "For instance, let’s look at what price band each product in the product table sits in, in $10 increments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "\n",
    "                SELECT \n",
    "                P_CODE, \n",
    "                P_PRICE,\n",
    "                ROUND((P_PRICE-5)/10,0)*10 as \"LOWER PRICE BAND\",\n",
    "                ROUND((P_PRICE+5)/10,0)*10 as \"UPPER PRICE BAND\"\n",
    "                FROM PRODUCT\n",
    "                ;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(sql_statement, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping product values into price bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this together with GROUP BY, we get a count of products in each price band.  The following query only calculates the lower price band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that in Oracle SQL a group by cannot refer to an alias\n",
    "# it would need to be written as: GROUP BY ROUND((P_PRICE-0.5)/10, 0)*10\n",
    "# or even better GROUP BY FLOOR(P_PRICE/10)*10 (because we can use \"FLOOR\" in Oracle)\n",
    "\n",
    "sql_statement = \"\"\"\n",
    "\n",
    "                SELECT \n",
    "                ROUND((P_PRICE-5)/10,0)*10 as \"LOWER PRICE BAND\",\n",
    "                COUNT(P_CODE) AS \"PRODUCT COUNT\"\n",
    "                FROM PRODUCT\n",
    "                GROUP BY \n",
    "                \"LOWER PRICE BAND\"\n",
    "                ORDER BY \"LOWER PRICE BAND\";\n",
    "\"\"\"\n",
    "\n",
    "product_bands = pd.read_sql_query(sql_statement, connection)\n",
    "product_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could quickly plot the result, for EDA purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_bands.set_index('LOWER PRICE BAND', inplace = True)\n",
    "product_bands.plot(kind = \"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is a little misleading as the x-axis does not reflect the full range of possible price bands.  We can use matplotlib methods to address this, primarily, the xticks method which will define the span of our plot.  (You may wonder how we know this stuff - we have spent a lot of time reading the documentation to solve various problems.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 6))\n",
    "plt.xticks(np.arange(0,280, step = 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this together with the data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 6))\n",
    "plt.xticks(np.arange(0,280, step = 10))\n",
    "plt.bar(product_bands.index, product_bands['PRODUCT COUNT'], \\\n",
    "        color = \"#7d16ea\", width = 10, align = 'edge' )\n",
    "plt.grid(which='major', axis='y', linestyle='dashed', linewidth=0.7);\n",
    "plt.title(\"Product counts by price band\")\n",
    "plt.xlabel('Price band ($)')\n",
    "plt.ylabel('Product count'); \n",
    "#the semi-colon will suppress the output of this final command.  Try removing it to see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Group products into price bands of $20, and plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping customer spend into bins\n",
    "\n",
    "More commonly, in the course of creating a single customer view, we might calculate each customer’s total spend.  We could then group up customers into spend bands. \n",
    "\n",
    "Let’s first look at how we find customer spend.  We need to link the customers in the invoice table to the spend in the line table.  The path is:\n",
    "\n",
    "Invoice------------------------------->Line\n",
    "\n",
    "Using:\n",
    "\n",
    "- I.INV_NUMBER = L. INV_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The spend on each line is found by multiplying the price by the number of units bought\n",
    "sql_statement = \"\"\"\n",
    "                SELECT\n",
    "                I.CUS_CODE,\n",
    "                I.INV_NUMBER, \n",
    "                L.LINE_UNITS*L.LINE_PRICE AS Spend_Per_Line\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                ;\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the amount each customer spent on each line in an invoice, we can add it up to get total spend by customer...here comes the GROUP BY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT \n",
    "                I.CUS_CODE, \n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS Total_Spend\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY \n",
    "                I.CUS_CODE\n",
    "                ;\n",
    "                \"\"\"\n",
    "tot_cust_spend = pd.read_sql_query(sql_statement, connection)\n",
    "tot_cust_spend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could take this further, and group total spend into spend bands and get the number of customers in each band.\n",
    "\n",
    "We will group by bands of $250 in this example.  \n",
    "\n",
    "We could either create a temporary table from the result in the previous slide and query that, or we could turn our previous query into a subquery as below...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT\n",
    "                ROUND((SUBQ.Total_Spend-125)/250,0)*250 as \"Lower Spend Band\",\n",
    "                ROUND((SUBQ.Total_Spend+125)/250,0)*250 as \"Upper Spend Band\",\n",
    "                COUNT(SUBQ.CUS_CODE) as \"Customer Count\"\n",
    "                FROM\n",
    "\n",
    "\n",
    "                (SELECT \n",
    "                I.CUS_CODE, \n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS Total_Spend\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY \n",
    "                I.CUS_CODE) SUBQ \n",
    "\n",
    "                GROUP BY \n",
    "                \"Lower Spend Band\",\n",
    "                \"Upper Spend Band\"\n",
    "                ORDER BY \"Lower Spend Band\";\n",
    "\n",
    "\"\"\"\n",
    "cust_bands = pd.read_sql_query(sql_statement, connection)\n",
    "cust_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot going on in that query, let's break it down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, note that because the outer query is selecting from the result set produced by our subquery, we need to refer to the subquery columns using the subquery alias:\n",
    "\n",
    "\n",
    "                SELECT\n",
    "                ROUND((SUBQ.Total_Spend-125)/250,0)*250 as \"Lower Spend Band\",\n",
    "                ROUND((SUBQ.Total_Spend+125)/250,0)*250 as \"Upper Spend Band\",\n",
    "                COUNT(SUBQ.CUS_CODE) as \"Customer Count\"\n",
    "                FROM\n",
    "\n",
    "- This is the subquery - it is the same query we ran just before. It has been given the alias \"SUBQ\":\n",
    "\n",
    "                (SELECT \n",
    "                I.CUS_CODE, \n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS Total_Spend\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY \n",
    "                I.CUS_CODE) SUBQ \n",
    "\n",
    "- The final group by is a grouping of the result of the outer query so it refers to the outer query columns.\n",
    "- We have to group on both bands as they are not being aggregated.  \n",
    "\n",
    "                GROUP BY \n",
    "                \"Lower Spend Band\",\n",
    "                \"Upper Spend Band\"\n",
    "                ORDER BY \"Lower Spend Band\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our customers according to how many are in each spend bin.  The plot is not the most interesting one.  Usually we would get a sense of the distribution of customers and make changes to the size of our bins according to what we see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_bands[['Lower Spend Band', 'Customer Count']].set_index('Lower Spend Band')\\\n",
    ".plot(kind = \"bar\", align = 'edge');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product plot gives a better idea of how we might use such a plot to choose groupings based on value bands - there are possibly three groups here - Up to \\\\$50, \\\\$50-\\\\$120, and \\\\$120+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 6))\n",
    "plt.xticks(np.arange(0,280, step = 10))\n",
    "plt.bar(product_bands.index, product_bands['PRODUCT COUNT'], \\\n",
    "        color = \"#7d16ea\", width = 10, align = 'edge' )\n",
    "plt.grid(which='major', axis='y', linestyle='dashed', linewidth=0.7);\n",
    "plt.title(\"Product counts by price band\")\n",
    "plt.xlabel('Price band ($)')\n",
    "plt.ylabel('Product count'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas to look at distributions\n",
    "Note that to visualise a distribution with python/pandas, we can simply use a histogram to similar effect. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A histogram for product prices\n",
    "product.P_PRICE.hist(bins = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for total customer spend\n",
    "tot_cust_spend.Total_Spend.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose the number of bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cust_spend.Total_Spend.hist(bins = 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can define bin sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tot_cust_spend.Total_Spend, bins=[0, 100, 200, 300, 400, 500]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFM with SQLite\n",
    "RFM analysis is a way of segmenting customers based on their purchasing habits.  Customers are classified according to time since last transaction (Recency), how many times they have transacted in a given period - e.g. in the last 12 months - (Frequency), and what their total spend was over that period (Monetary).\n",
    "\n",
    "Note that before we classify customers:\n",
    "\n",
    "- we need to know what our customers raw RFM values are (i.e. what is their total spend, recency and frequency)\n",
    "- we need to figure out what bin sizes we will use (which is  we did before) \n",
    "\n",
    "At which point we can classify our customers into the bins depending on the raw RFM values.\n",
    "\n",
    "We have already figured out good bin sizes for Monetary above (total customer spend) using a subquery.  \n",
    "\n",
    "This time we are going to makes things a bit simpler.  We are going to create a CUSTOMER_RFM table that has all of the raw aggregates we need in it.  We can then directly query that table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Customer RFM Table\n",
    "We are going to create a view of our customers that includes their raw recency, frequency and monetary values. We will use those values to classify our customers a bit later.\n",
    "\n",
    "First, let's look how we get to the Recency, Frequency and Monetary values one by one before we bring it all into one table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency\n",
    "This is the number of days since the last transaction for each customer.  \n",
    "\n",
    "I am assuming that we are interested in the most recent purchase with reference to the end of the financial year.\n",
    "\n",
    "Note that to find days between two dates in SQLite, we need to convert them to julian dates.  In Oracle, we would use the TO_DATE function to convert the string '2019-03-31' to a date and simply subtract one date from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT \n",
    "                CUS_CODE, \n",
    "                julianday('2019-03-31')-MAX(julianday(INV_DATE)) AS Recency\n",
    "                FROM INVOICE\n",
    "                GROUP BY CUS_CODE;\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency\n",
    "Let's look at the frequency for each customer.\n",
    "\n",
    "All we need to know is in the invoice table (invoice number and customer code).  We simply need to count the number of invoices a customer has generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT \n",
    "                \n",
    "                CUS_CODE,\n",
    "                COUNT(INV_NUMBER) AS Frequency\n",
    "                FROM INVOICE \n",
    "                GROUP BY CUS_CODE\n",
    "                ;\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monetary\n",
    "We already worked out the monetary calculation (total customer spend) in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT \n",
    "                I.CUS_CODE, \n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS Monetary\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY \n",
    "                I.CUS_CODE\n",
    "                ;\n",
    "                \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it altogether into an customer RFM table\n",
    "\n",
    "We can bring all of the above queries together to create a single customer RFM table containing all of these values, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.execute('DROP TABLE IF EXISTS CUSTOMER_RFM')\n",
    "\n",
    "sql_statement = \"\"\"\n",
    "                CREATE TABLE CUSTOMER_RFM\n",
    "                AS\n",
    "                SELECT \n",
    "                I.CUS_CODE, \n",
    "                \n",
    "                julianday('2019-03-31')-MAX(julianday(I.INV_DATE)) AS Recency,\n",
    "                COUNT(DISTINCT I.INV_NUMBER) AS Frequency,\n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS \"Monetary\"\n",
    "\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY I.CUS_CODE;\n",
    "                \"\"\"\n",
    "connection.execute(sql_statement)\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That statement needs some explaining:\n",
    "\n",
    "- First, note that we can create a table from the result set of a query:\n",
    "\n",
    "\n",
    "               CREATE TABLE CUSTOMER_RFM\n",
    "               AS\n",
    "               SELECT \n",
    "               I.CUS_CODE,\n",
    "\n",
    "- Second, note the COUNT(DISTINCT...) here.  We need to be careful – our join will return some invoice numbers multiple times as there will be a row per invoice line item, so we need to be sure to count distinct invoice numbers\n",
    "\n",
    "- Third, note that these are the aggregates that we will use for our classification.\n",
    "\n",
    "                julianday('2019-03-31')-MAX(julianday(I.INV_DATE)) AS Recency,\n",
    "                COUNT(DISTINCT I.INV_NUMBER) AS Frequency,\n",
    "                SUM(L.LINE_UNITS*L.LINE_PRICE) AS \"Monetary\"\n",
    "\n",
    "- Fourth, note we are joining invoice to line\n",
    "\n",
    "                FROM INVOICE I JOIN LINE L\n",
    "                ON(I.INV_NUMBER = L.INV_NUMBER)\n",
    "                GROUP BY I.CUS_CODE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Display the CUSTOMER_RFM table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing bin sizes - Recency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to decide on bins for our data.  In reality we could eyeball this data and decide, but let's assume it is a large dataset and we cannot do that.  First we are going to create bins using SQL - trying out bins of size ten.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "            SELECT \n",
    "            ROUND((Recency-5)/10,0)*10 AS \"Recency Band Lower\",\n",
    "            ROUND((Recency+5)/10,0)*10 AS \"Recency Band Upper\",\n",
    "            COUNT(CUS_CODE) AS \"Customer Count\"\n",
    "            FROM\n",
    "            CUSTOMER_RFM\n",
    "            \n",
    "            GROUP BY \n",
    "            \"Recency Band Lower\", \n",
    "            \"Recency Band Upper\"\n",
    "            ORDER BY \"Recency Band Lower\";\n",
    "\n",
    "\"\"\"\n",
    "recency_binned = pd.read_sql_query(sql_statement, connection)\n",
    "recency_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Plot the recency_binned dataframe created above.  For comparison, do the same with a pandas histogram using the un-binned recency data (the Recency column in the CUSTOMER_RFM table). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency bin size decision\n",
    "Let's stick with bins of size 10 for Recency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing bin sizes - Frequency\n",
    "\n",
    "You won't need to calculate a ceiling or floor for Frequency as you will be grouping by count.  In FMCG analyses it would make sense to create bands for frequency as customers tend to make many visits, but this is not the case in this tiny dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT\n",
    "                Frequency,\n",
    "                COUNT(CUS_CODE) \n",
    "                AS \"Customer count\"\n",
    "                FROM\n",
    "                CUSTOMER_RFM\n",
    "                \n",
    "                GROUP BY \n",
    "                Frequency\n",
    "                ORDER BY Frequency\n",
    "                ;\n",
    "                \"\"\"\n",
    "frequency_binned = pd.read_sql_query(sql_statement, connection)\n",
    "frequency_binned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Plot the binned frequency result set you just created with SQLite.  For comparison, do the same with a pandas histogram using the un-binned frequency data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency bin size decision\n",
    "Our \"bin sizes\" will be of size one in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing bin sizes - Monetary \n",
    "\n",
    "We have already done this, but let's do it again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "                SELECT ROUND((Monetary-125)/250,0)*250 AS \"Monetary Band Lower\",\n",
    "                ROUND((Monetary+125)/250,0)*250 AS \"Monetary Band Upper\",\n",
    "                COUNT(CUS_CODE) AS \"Customer Count\"\n",
    "                FROM\n",
    "                CUSTOMER_RFM\n",
    "                \n",
    "                GROUP BY \n",
    "                \"Monetary Band Lower\"\n",
    "                ORDER BY \"Monetary Band Lower\", \"Monetary Band Upper\"\n",
    "                ;\n",
    "                \"\"\"\n",
    "monetary_binned = pd.read_sql_query(sql_statement, connection)\n",
    "monetary_binned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monetary bin size decision\n",
    "We will stick with bins of size $250.  \n",
    "\n",
    "With a real-world dataset, we would be experimenting with different bin sizes for all three categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM crosstab\n",
    "Once we have experimented with different bands and looked at the distribution of customer counts within them, we can build an RFM table according to our chosen cut-offs.  We can then classify our customers and populate the RFM crosstab with counts (or percentages) and make decisions around how we would like to group these customers according to behaviours.  Below is a very basic attempt at this which only uses one of the dimensions (Recency):\n",
    "\n",
    "\n",
    "![](../figures/RFM.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying our customers using CASE statements\n",
    "\n",
    "We have the raw RFM aggregates for our customers, and we have decided on bin sizes.  Now we can classify our customers into bins.  Here we will be usign CASE statements.\n",
    "\n",
    "With PL/SQL you have access to functionality that you get with procedural programming languages, namely control flow statements, user defined functions, variables and loops.  Additionally with PL/SQL we can create stored procedures.\n",
    "\n",
    "SQLite does not directly support PL/SQL, however CASE statements can be used.  A case statement is a way of writing a control flow (if/else) statement without having to call a procedure. Case statements are also used in Oracle SQL\n",
    "\n",
    "The basic syntax is:\n",
    "\n",
    "   >WHEN *CONDITION 1* THEN *VALUE 1*<br/>\n",
    "   >WHEN *CONDITION 2* THEN *VALUE 2*<br/>\n",
    "   >WHEN *CONDITION 3* THEN *VALUE 3*<br/>\n",
    "   >...<br/>\n",
    "   >ELSE *VALUE N*<br/>\n",
    "   >END\n",
    "\n",
    "Case statements are often used with a select statement to define column values, they can also be used to update column values.\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE Statements with SELECT\n",
    "Example with SELECT – Classify customers according to frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "        SELECT \n",
    "        CUS_CODE, \n",
    "        COUNT(INV_NUMBER) AS Frequency,\n",
    "        CASE \n",
    "            WHEN COUNT(INV_NUMBER) = 1 THEN 'Not frequent'\n",
    "            WHEN COUNT(INV_NUMBER) = 2 THEN 'Kind of frequent'\n",
    "            ELSE 'Best customer'\n",
    "        END Frequency_class\n",
    "        FROM\n",
    "        INVOICE\n",
    "        GROUP BY CUS_CODE\n",
    "        ;\n",
    "        \"\"\"\n",
    "pd.read_sql_query(sql_statement, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE Statements with UPDATE\n",
    "We can also use a case statement to update a table.  We are going to add classifications to the CUSTOMER_RFM table we created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from CUSTOMER_RFM', connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we add columns to our table ready for our classifications (these are the columns we will update with case statements):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_statement = 'ALTER TABLE CUSTOMER_RFM ADD COLUMN Recency_Class NUMBER(3)'\n",
    "cursor.execute(sql_statement)\n",
    "sql_statement = 'ALTER TABLE CUSTOMER_RFM ADD COLUMN Frequency_Class VARCHAR(2)'\n",
    "cursor.execute(sql_statement)\n",
    "sql_statement = 'ALTER TABLE CUSTOMER_RFM ADD COLUMN Monetary_Class VARCHAR(20)'\n",
    "cursor.execute(sql_statement)\n",
    "\n",
    "\n",
    "#commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from CUSTOMER_RFM', connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for an update using a case statement.  We will update recency first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_statement = \"\"\"\n",
    "        UPDATE CUSTOMER_RFM\n",
    "        SET Recency_Class = \n",
    "            CASE \n",
    "                WHEN Recency < 10 THEN 'Up to 10'\n",
    "                WHEN Recency < 20 THEN '10-20'\n",
    "                WHEN Recency < 30 THEN '20-30'\n",
    "                ELSE '30+'\n",
    "            END;\n",
    "    \"\"\"\n",
    "connection.execute(sql_statement)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from CUSTOMER_RFM', connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write and run two more updates so that your Frequency_Class and Monetary_Class columns look like this:\n",
    "\n",
    "| CUS_CODE | ... |Frequency_Class | Monetary_Class | \n",
    "| --- | --- | --- | --- |\n",
    "|10011| ... | 3 | 250 - 500 | \n",
    "|10012| ... | 1 | Up to 250 | \n",
    "|10014| ... | 2 | 250 - 500 | \n",
    "|10015| ... | 1 | Up to 250 | \n",
    "|10018| ... | 1 | Up to 250 | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** This one may take a while...\n",
    "\n",
    "Save your CUSTOMER_RFM table into a pandas dataframe object.  Use pandas grouping or pivoting or crosstab with some reshaping techniques (and probably a fillna(0) somewhere along the way) to create an RFM table like this:\n",
    "\n",
    "\n",
    "| . | Monetary ($) |250-500 | Up to 250 | \n",
    "| --- | --- | --- | --- |\n",
    "| **Recency(days)** | **Frequency** |. | .| \n",
    "|20-30| 1 | 0 | 1 |\n",
    "|.| 2 | 0 | 0 |\n",
    "|.| 3 | 0 | 0 |\n",
    "|10-20| 1 | 0 | 1 |\n",
    "|.| 2 | 1 | 0 |\n",
    "|.| 3 | 0 | 0 |\n",
    "|Up to 10| 1 | 0 | 1 |\n",
    "|.| 2 | 0 | 0 | \n",
    "|.| 3 | 1 | 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An analysis of a larger dataset might have yielded this result (converted to percentages)\n",
    "\n",
    "| . | Monetary ($) | Up to 250 | 250-500 | 500+ |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **Recency(days)** | **Frequency** | . | . | . | \n",
    "|6 months +| 1-5 | 10\\% | 4\\% | 1\\%|\n",
    "|. | 6-10 | 4\\% | 6\\% | 3\\% |\n",
    "|. | 11+ | 1\\% | 2\\% | 1\\% |\n",
    "|2-6 months | 1-5 | 1\\% | 2\\% | 3\\% |\n",
    "|. | 6-10 | 5\\% | 7\\% | 5\\% |\n",
    "|. | 11+ | 2\\% | 1\\% | 7\\%|\n",
    "|Up to 2 months | 1-5 | 11\\% | 1\\% | 9\\% |\n",
    "|. | 6-10 | 1\\% | 1\\% | 4\\% |\n",
    "|. | 11+ | 0\\% | 3\\% | 5\\% |\n",
    "\n",
    "\n",
    "At this point in the analysis you would use this table to help define customer segments, and you would give those segments names.  This is out of the course scope – but you are welcome to try!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercise - Visits to store, target product\n",
    "\n",
    "For this exercise, you will need to load in basket_table.csv and transaction_table.csv which you can download from the datasets folder.\n",
    "\n",
    "Try the exercise with SQLite, and then replicate with pandas\n",
    "\n",
    "- A department store has aggressively promoted a target product and would like to compare the spend of customers in their loyalty program who purchased that product vs those in their loyalty program who did not.  (note that they are limited to investigating loyalty customers as non-loyalty customers cannot be uniquely identified).\n",
    "- The target product code is 'AX34'\n",
    "- They are interested in spend-per-visit, not spend-per-transaction.  A department store has many counters, and in one visit a customer may visit more than one counter and make a transaction.  A single visit is defined as transaction/s made on the same day by the same person. \n",
    "- Your task is to:\n",
    "    - Create and populate basket and transaction SQL tables with the csvs given\n",
    "    - Inspect the tables to understand how they relate\n",
    "    - Create a visits table that looks like this (including a flag identifying whether the target product was bought in a visit):\n",
    "\n",
    "| CUS_CODE | TRANS_DATE | VISIT_TOTAL | BOUGHT_TARGET | \n",
    "| --- | --- | --- | --- |\n",
    "104 | 04/02/2019 | 374.9 | 1 |\n",
    "100 | 01/02/2019 | 146.9 | 1 | \n",
    "102 | 05/02/2019 | 2.3 | 0 |\n",
    "100 | 04/02/2019 | 234.6 | 1 |\n",
    "103 | 03/02/2019 | 10.8 | 0 |\n",
    "101 | 05/02/2019 | 401.8 | 1 |\n",
    "101 | 02/02/2019 | 357.3 | 1 |\n",
    "101 | 01/02/2019 | 56.7 | 0 |\n",
    "100 | 03/02/2019 | 135.2 | 1 |\n",
    "104 | 05/02/2019 | 215.6 | 0 |\n",
    "\n",
    "\n",
    "- Work out the average spend per visit where the target product was purchased vs when it was not\n",
    "\n",
    "| Ave visit spend target |  \n",
    "| --- |\n",
    "275.12|\n",
    "\n",
    "| Ave visit spend not target |  \n",
    "| --- |\n",
    "71.35|\n",
    "\n",
    "- Work out the average overall spend of those who bought the target product at least once in the period vs those who did not\n",
    "\n",
    "| Ave period spend target |  \n",
    "| --- |\n",
    "641|\n",
    "\n",
    "| Ave period spend not target |  \n",
    "| --- |\n",
    "6.55|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in transaction_table.csv and basket_table.csv with pandas and then use a pandas to_sql method \n",
    "# to create and populate two database tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to create the visits table if you are stuck ...\n",
    "\n",
    "# Do a select  from a subquery\n",
    "# The subquery would query the basket table.\n",
    "# It would sum up transaction totals, and flag whether or not a target product was purchased \n",
    "# in a transaction (hint try MAX(Case when ...)) and then group by transaction ID.\n",
    "# The outer select would select customer and date from the transaction table and \n",
    "# the sum of the totals in the subquery and the max target flag from the sub query.  \n",
    "# To get the date and the customer code, a join to the transactions table would be needed\n",
    "# The outer select would group by transaction date and customer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average spend per visit where the target product was purchased \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average spend per visit where the target product was not purchased \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average overall spend of those who bought the target product at least once in the period\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average overall spend of those who did not buy the target product at least once in the period\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require(['base/js/utils'],\n",
    "function(utils) {\n",
    "   utils.load_extensions('calico-spell-check', 'calico-document-tools', 'calico-cell-tools');\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

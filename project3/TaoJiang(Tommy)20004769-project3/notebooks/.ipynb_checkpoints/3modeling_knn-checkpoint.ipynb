{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling : KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Load the data and analysis libraries\n",
    "\n",
    "> ### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "# import gc\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\t\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### We are using the local test from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOCAL_DEMO = True\n",
    "# IS_LOCAL_DEMO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lags = 57\n",
    "last_day = 1913  \n",
    "fday = datetime(2016,4, 25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### load processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: train_data.csv.gz\n"
     ]
    }
   ],
   "source": [
    "data_file = (\"train_data.csv.gz\" if(IS_LOCAL_DEMO) else \"train_data.csv\")\n",
    "dt = pd.read_csv(data_file)\n",
    "\n",
    "print(\"loading:\",data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"date\"] = pd.to_datetime(dt[\"date\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### We are using the deep copy to save the data temporarily for the sliding window model to reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dt.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### To avoid the model we constructed overfitting, we did not use the previous day to predict rather than created more means as new features. The 7_28 refers to the average of the first 7 days of the last cycle (7), that is, log = 7, wins = 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):  # [(7, lag_7), (28, lag_28)]\n",
    "        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)  \n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean()) \n",
    "\n",
    "    date_features = {\"wday\": \"weekday\", \"week\": \"weekofyear\", \"month\": \"month\",\"quarter\": \"quarter\",  \"year\": \"year\",\"mday\": \"day\" }\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fea(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'd',\n",
       "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_7', 'lag_28',\n",
       "       'rmean_7_7', 'rmean_28_7', 'rmean_7_28', 'rmean_28_28', 'week',\n",
       "       'quarter', 'mday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 31)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Split the dataset to training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + [\"event_type_1\", \"event_type_2\"]\n",
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\", 'event_name_1', 'event_name_2']\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "# print(train_cols)\n",
    "X_train = df[train_cols]\n",
    "y_train = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>...</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  dept_id  store_id  cat_id  state_id  wday  month  year  \\\n",
       "550000        0        0         0       0         0     1      4  2016   \n",
       "550001        0        0         0       0         0     2      4  2016   \n",
       "550002        0        0         0       0         0     3      4  2016   \n",
       "\n",
       "        event_type_1  event_type_2  ...  sell_price  lag_7  lag_28  rmean_7_7  \\\n",
       "550000             0             0  ...        8.38    1.0     1.0   1.571429   \n",
       "550001             0             0  ...        8.38    2.0     3.0   1.714286   \n",
       "550002             0             0  ...        8.38    0.0     1.0   1.714286   \n",
       "\n",
       "        rmean_28_7  rmean_7_28  rmean_28_28  week  quarter  mday  \n",
       "550000    1.000000    1.071429     1.035714    15        2    16  \n",
       "550001    1.428571    1.142857     1.142857    15        2    17  \n",
       "550002    1.571429    1.142857     1.035714    16        2    18  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Create a KNN Regressor model to training all selected features by Skit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsRegressor(3)\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Unsupervised learning can easily overfit the model. We try to use different weights to obtain the final predicted value to avoid overfitting. After multiple sets of random weight tests, the current optimal weight parameter is[1.035, 1.03, 1.025] on Kaggle.  Model optimization is highly dependent on weight hyperparameters. We need to use more random weight parameters to be optimized the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "if(IS_LOCAL_DEMO):\n",
    "    alphas = [1] # for local demo\n",
    "else:\n",
    "    alphas = [1.035, 1.03, 1.025] #[1.015,1.25,1.03] #[1.0,1.15,1.01] #[1.0,1.15,1.01] # for kaggle\n",
    "\n",
    "weights = [1 / len(alphas)] * len(alphas) \n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Build a loop for the sliding window model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-04-25 00:00:00\n",
      "0 2016-04-26 00:00:00\n",
      "0 2016-04-27 00:00:00\n",
      "0 2016-04-28 00:00:00\n",
      "0 2016-04-29 00:00:00\n",
      "0 2016-04-30 00:00:00\n",
      "0 2016-05-01 00:00:00\n",
      "0 2016-05-02 00:00:00\n",
      "0 2016-05-03 00:00:00\n",
      "0 2016-05-04 00:00:00\n",
      "0 2016-05-05 00:00:00\n",
      "0 2016-05-06 00:00:00\n",
      "0 2016-05-07 00:00:00\n",
      "0 2016-05-08 00:00:00\n",
      "0 2016-05-09 00:00:00\n",
      "0 2016-05-10 00:00:00\n",
      "0 2016-05-11 00:00:00\n",
      "0 2016-05-12 00:00:00\n",
      "0 2016-05-13 00:00:00\n",
      "0 2016-05-14 00:00:00\n",
      "0 2016-05-15 00:00:00\n",
      "0 2016-05-16 00:00:00\n",
      "0 2016-05-17 00:00:00\n",
      "0 2016-05-18 00:00:00\n",
      "0 2016-05-19 00:00:00\n",
      "0 2016-05-20 00:00:00\n",
      "0 2016-05-21 00:00:00\n",
      "0 2016-05-22 00:00:00\n",
      "0 1 1.0\n"
     ]
    }
   ],
   "source": [
    "sub = 0.\n",
    "cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):  # [(1.035, 0.333), (1.03, 0.333), (1.025, 0.333)]\n",
    "    te = dt # get the all dataset\n",
    "    for tdelta in range(0, 28):\n",
    "        day = fday + timedelta(days=tdelta)  # single predict day\n",
    "        print(icount, day)\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy() # get sliding window date of dataset  \n",
    "        create_fea(tst)\n",
    "        tst = tst.loc[tst.date == day , train_cols]  # sliding window select data\n",
    "        te.loc[te.date == day, \"sales\"] = alpha * model_knn.predict(tst) # train sliding window select data\n",
    "    \n",
    "    # formate\n",
    "    te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]]  \n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]  # [F1,F2,F3,...F28]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()  # change the formate same with the submission\n",
    "    te_sub.fillna(0., inplace = True) \n",
    "    te_sub.sort_values(\"id\", inplace = True)\n",
    "    te_sub.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "     # Calculation weighting\n",
    "    if icount == 0 :\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight \n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight\n",
    "    print(icount, alpha, weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Create validation and evaluation the same with sample submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub.shape)\n",
    "print(sub.columns)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Dataset persistence\n",
    ">###  Save the data frame to the hard drive and use the \"4agg-12lelvel\" script to generate and upload it to The Kaggle for final score evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(IS_LOCAL_DEMO_LOCAL_DEMO):\n",
    "    train_data.to_csv(\"submission_knn.csv.gz\",compression='gzip',index=False)# for local demo\n",
    "else:\n",
    "    train_data.to_csv(\"submission_knn.csv\",index=False) # for kaggle  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
